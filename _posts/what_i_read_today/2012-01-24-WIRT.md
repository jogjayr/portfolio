---
layout: post
category: links
title: Should Everyone Else Just Give Up?
teaser:  Apple has more money than Scrooge McDuck, Ali Baba and Richie Rich, combined
tags: [link, summary, tech]
---

###Apple Makes a F\*ckload of Money

Noted blogger, venture capitalist and Apple (Designed in California&trade;) fanboy MG Siegler called Apple's first quarter 2012 results 
["A 'Holy Fucking Shit' Quarter"](http://parislemon.com/post/16424622119/a-holy-fucking-shit-quarter). The numbers
are impressive indeed; $13 billion profits on $46 billion sales. Or in other words, more money than God. 

They now have close to a $100 billion in the bank. It might not be a bad idea for the EU to ask them for a bailout.
Or help other poor people. C'mon people. You can re-open the charity department again. And give someone else a chance to win.


###I, for one, welcome our new robot drivers

A [great](http://www.wired.com/magazine/2012/01/ff_autonomouscars/all/1) [deal](http://www.nytimes.com/2012/01/24/technology/googles-autonomous-vehicles-draw-skepticism-at-legal-symposium.html) 
of [press](http://www.thestar.com/article/1120427--bmw-creates-robot-car-that-can-drive-itself) recently has made it clear that
autonomous cars are just around the corner. The NYT covered a symposium dedicated to the legal implications of this new technology.
The benefits are clear: safety, fuel and time efficiency, greater car-sharing and privacy for sexy times in the
backseat without having to rent a limo. 

It's safe to say that this technology is at least 6 years away from even narrow-spread adoption. Nevada is the only state, so far,
to legalize autonomously driven cars. Other state legislatures will begin to consider the issue over the next couple of years.

I think that all the other issues: insurance, police stops, deer on the road and even the Chinese restaurant/stop sign
problem (I don't know if they're the same thing, but have superficial similarities in that sharing access to a resource leads to
a starvation condition and indefinite waiting), will work themselves out eventually. What I'm curious about is the process
used to certify or give a "driver's license" to these programs. Will they be held to the same standards that human beings are?
Is it really possible to verify that a driving program has no bugs and will perform perfectly under all conditions?
Or will it just be "good enough" if the program is better than the "average driver"? 

Here we get into thorny territory. Google have claimed that their car has driven 200,000 miles without accidents, but that's
not really statistically significant (unless they have more data they haven't released yet). In [1995](http://www.motorists.org/other/crash-data) 
(yes, I know, old as hell, but I'm lazy), the US had 1.5 fatal accidents per 100 million vehicle miles. If anyone wants to do
more detailed analysis, they are welcome to, but 200k is hardly conclusive that the program is safe. Unless...

More speculation here: I'm no computer vision expert; is it possible to train such a system on video data? 
If it is, then Google must have a wealth of such data, thanks to StreetView. And in that case, the system may only 
have driven 200,000 real world miles but tested on many many more. 


